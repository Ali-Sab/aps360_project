{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ali-Sab/aps360_project/blob/main/APS360_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLSzgr-8DSUr",
    "outputId": "81359ee1-857b-433b-a3ee-8ebc1cb06669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc3a44c2e70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "torch.manual_seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bevxoaRrb2J-"
   },
   "outputs": [],
   "source": [
    "# import audio libraries\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "\n",
    "import librosa\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa import power_to_db\n",
    "from librosa.effects import trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RVI7aS9Eb2KD"
   },
   "outputs": [],
   "source": [
    "#Plot size\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KfTO1huZmGl-"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/team_data.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5d251436816c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_data_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/team_data.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/team_data.zip'"
     ]
    }
   ],
   "source": [
    "#Download team data from Google Drive\n",
    "if(not os.path.exists(\"/team_data.zip\")):\n",
    "    team_data_url = \"https://drive.google.com/uc?export=download&id=1eycnGtDVzqW57EUBEQmJDPz2F1Dqgqdc\"\n",
    "\n",
    "    resp = requests.get(team_data_url, stream=True)\n",
    "\n",
    "    with open(\"/team_data.zip\", 'wb') as fd:\n",
    "        for chunk in resp.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2e0Ulj3wnHs_"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/KaggleFSDD.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ccb86e4b5825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkaggle_data_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/KaggleFSDD.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/KaggleFSDD.zip'"
     ]
    }
   ],
   "source": [
    "#Download Kaggle data from Google Drive\n",
    "if(not os.path.exists(\"/KaggleFSDD.zip\")):\n",
    "    kaggle_data_url = \"https://drive.google.com/uc?export=download&id=1Uoy-XzAqE12FIPdqf9adFz7dfTcjDI9N\"\n",
    "\n",
    "    resp = requests.get(kaggle_data_url, stream=True)\n",
    "\n",
    "    with open(\"/KaggleFSDD.zip\", 'wb') as fd:\n",
    "        for chunk in resp.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvfK2yuqonvQ",
    "outputId": "a20aeed9-3c4b-481f-afa9-a759cdef0194"
   },
   "outputs": [],
   "source": [
    "if(not os.path.exists(\"/content/team_recordings\")):\n",
    "    !unzip '/team_data.zip' -d '/content/team_recordings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bur1GUospsS7",
    "outputId": "8d03784e-d98c-477b-fa8c-b75e65e2ca62"
   },
   "outputs": [],
   "source": [
    "if(not os.path.exists(\"/content/kaggle_recordings\")):\n",
    "    !unzip '/KaggleFSDD.zip' -d '/content/kaggle_recordings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bue4-gKlb2KG"
   },
   "outputs": [],
   "source": [
    "# load audio files\n",
    "def load_files(files, X, y):\n",
    "  for file in files:\n",
    "      label = int(file.split(\"_\")[0])\n",
    "      rate, data = wavfile.read(join(dir, file))\n",
    "      X.append(data.astype(np.float32))\n",
    "      y.append(label)\n",
    "  return rate\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# load team recordings\n",
    "dir = '/content/team_recordings/all'\n",
    "files = listdir(dir)\n",
    "rate1 = load_files(files, X, y)\n",
    "\n",
    "# load Kaggle recordings\n",
    "dir = '/content/kaggle_recordings/recordings'\n",
    "files = listdir(dir)\n",
    "rate2 = load_files(files, X, y)\n",
    "\n",
    "rate = min(rate1, rate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "ZI-uNy4-b2KJ",
    "outputId": "de64b083-1a9d-4dd3-b817-47af9e1ca089"
   },
   "outputs": [],
   "source": [
    "# check distribution of length of audio clips\n",
    "\n",
    "def show_length_distribution(signals, rate=8000):\n",
    "    sample_times = [len(x)/rate for x in signals]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.hist(x=sample_times, bins = 'fd')\n",
    "    fig.suptitle('Audio signal lengths')\n",
    "    plt.xlabel('Duration (seconds)')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.show()\n",
    "    return sample_times\n",
    "\n",
    "lengths = show_length_distribution(X)\n",
    "print(np.percentile(lengths, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-6LK7hnb2KP"
   },
   "outputs": [],
   "source": [
    "# pad all clips to same length\n",
    "\n",
    "N = int(rate * 0.7)\n",
    "X_uniform = []\n",
    "for x in X:\n",
    "    if len(x) < N:\n",
    "        X_uniform.append(np.pad(x, (0, N - len(x)), constant_values = (0, 0)))\n",
    "    else:\n",
    "        X_uniform.append(x[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "LDh5Xp4eb2KR",
    "outputId": "c8e9a17b-fed5-47b5-fb3f-643d4cb07027"
   },
   "outputs": [],
   "source": [
    "# playback some audio clips\n",
    "\n",
    "index = 3\n",
    "print(\"Digit: {}\".format(y[index]))\n",
    "plt.plot(X_uniform[index])\n",
    "plt.show()\n",
    "ipd.Audio(X_uniform[index], rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "mCU156-Lb2KS",
    "outputId": "3cce94f3-399b-4476-86dd-f90d5db43aa7"
   },
   "outputs": [],
   "source": [
    "from librosa import display\n",
    "#S = librosa.util.normalize(X_uniform[4])      makes no difference to normalize...\n",
    "S = librosa.feature.melspectrogram(y=X_uniform[4], sr=8000)\n",
    "print(S.shape)\n",
    "print(S)\n",
    "display.specshow(librosa.power_to_db(S, ref=np.max), x_axis='time', y_axis='mel', fmin=25, fmax=280)\n",
    "\n",
    "#from scipy import signal\n",
    "#frequencies, times, spectrogram = signal.spectrogram(X_uniform[4], 8000)\n",
    "#plt.pcolormesh(times, frequencies, spectrogram)\n",
    "#plt.imshow(spectrogram)\n",
    "#plt.ylabel('Frequency [Hz]')\n",
    "#plt.xlabel('Time [sec]')\n",
    "\n",
    "#plt.show()\n",
    "#for x in X_uniform[0]:\n",
    "#   print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sHE7lC_rEM0M"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Form the training, validation, and test sets\n",
    "def get_data_sets(data, labels, training_percentage=0.7, use_mel=False):\n",
    "  # subtraction is necessary below because we are using integers and do not want any data to be unused because of rounding down the integers\n",
    "  train_len = int(len(data)*training_percentage)\n",
    "  val_len = int(len(data)*(1-training_percentage)/2)\n",
    "  test_len = len(data) - train_len - val_len\n",
    "  \n",
    "  if(use_mel):\n",
    "      # Get melspectrograms of each sample\n",
    "      mel_list = []\n",
    "      for i in range(len(data)):\n",
    "          S = librosa.feature.melspectrogram(y=data[i], sr=8000)\n",
    "          S = S.flatten()\n",
    "          mel_list.append(S)\n",
    "      x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(mel_list, labels, test_size=val_len, random_state=1)\n",
    "  else:\n",
    "      x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(data, labels, test_size=val_len, random_state=1)\n",
    "\n",
    "  x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x_train, y_train, test_size=test_len, random_state=1)\n",
    "\n",
    "  return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "# Calc\n",
    "def get_accuracy(classifier, x_data, y_data):\n",
    "    pred = rfc.predict(x_data)\n",
    "    correct = 0\n",
    "    total = len(pred)\n",
    "    for i in range(len(pred)):\n",
    "        correct += pred[i] == y_data[i]\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "def get_accuracy_by_class(classifier, x_data, y_data):\n",
    "    pred = rfc.predict(x_data)\n",
    "    correct = 0;\n",
    "    total = len(pred)\n",
    "    for i in range(len(pred)):\n",
    "        correct += pred[i] == y_data[i]\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-ecVBYuOlZR",
    "outputId": "a80af97b-82aa-436f-bdba-4969bc727d62"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_uniform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5cdc553f8d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_uniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_uniform' is not defined"
     ]
    }
   ],
   "source": [
    "#For baseline model, will need to implement random forest classifier\n",
    "#Will use the following links as guides: (moreso the second link)\n",
    "#https://medium.com/@pratyush.sinha/training-random-forest-by-back-propagation-for-fun-pytorch-part-1-a54674355aa7\n",
    "#https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=10, n_estimators=100, max_features=100, warm_start=True, min_samples_leaf=10, verbose=True, n_jobs=-1)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_data_sets(X_uniform, y, use_mel=True)\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QegF0qFctDwY",
    "outputId": "0060da34-c31b-420e-8bee-077672aff2fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 89.1025641025641%\n",
      "Test Accuracy: 89.74358974358975%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Accuracy: {}%\".format(100*get_accuracy(rfc, x_val, y_val)))\n",
    "print(\"Test Accuracy: {}%\".format(100*get_accuracy(rfc, x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qWPAIiiZb2KV"
   },
   "outputs": [],
   "source": [
    "# After receiving necessary tensors\n",
    "\n",
    "def get_data_loader(data, batch_size, training_percentage=0.7):\n",
    "  # subtraction is necessary below because we are using integers and do not want any data to be unused because of rounding down the integers\n",
    "  train_len = int(len(data)*training_percentage)\n",
    "  val_len = int(len(data)*(1-training_percentage)/2)\n",
    "  test_len = len(data) - train_len - val_len\n",
    "  train_set, val_set, test_set = torch.utils.data.random_split(data, [train_len, val_len, test_len])\n",
    "\n",
    "  train_loader = DataLoader(train_set, batch_size, shuffle=True)\n",
    "  if val_len > 0:\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle=True)\n",
    "  else:\n",
    "    val_loader = []\n",
    "  if test_len > 0:\n",
    "    test_loader = DataLoader(test_set, batch_size, shuffle=True)\n",
    "  else:\n",
    "    test_loader = []\n",
    "\n",
    "  return train_loader, val_loader, test_loader\n",
    "\n",
    "batch_size = 64\n",
    "#dataset = TensorDataset(torch.from_numpy(datanp))\n",
    "#dataset = TensorDataset(data)\n",
    "#train_loader, val_loader, test_loader = get_data_loader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7VYmIwC9b2KZ"
   },
   "outputs": [],
   "source": [
    "#For baseline model, will need to implement random forest classifier\n",
    "#Will use the following links as guides: (moreso the second link)\n",
    "#https://medium.com/@pratyush.sinha/training-random-forest-by-back-propagation-for-fun-pytorch-part-1-a54674355aa7\n",
    "#https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=10, n_estimators=100, max_features=100, warm_start=True, min_samples_leaf=10, verbose=True, n_jobs=-1)\n",
    "\n",
    "#Because we set warm start to true, we can fit the decision trees batch by batch\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs=1):\n",
    "    acc = np.zeros(num_epochs)\n",
    "    for epoch in range(num_epochs):    #I don't think we even need more than one, but try it and see cuz idk\n",
    "        for input, labels in enumerate(train_loader, 0):\n",
    "            #replace 784 with number of pixels per spectrogram... idk how many as of yet\n",
    "            input = input.view(-1, 784)\n",
    "            model.fit(input, labels)\n",
    "        acc[epoch] = get_accuracy(model, val_loader)\n",
    "\n",
    "    #rough stuff\n",
    "    print(acc)\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ui6xYaqCb2Kd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "APS360 Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
